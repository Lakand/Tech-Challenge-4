# ğŸ“ˆ Tech Challenge - Fase 4: Stock Prediction API

Este projeto consiste em uma soluÃ§Ã£o End-to-End de Machine Learning Engineering desenvolvida para o Tech Challenge da Fase 4 (PÃ³s-Tech FIAP).

O objetivo Ã© prever preÃ§os de fechamento de aÃ§Ãµes utilizando redes neurais LSTM (Long Short-Term Memory), servidas por uma API RESTful modularizada, conteinerizada e monitorada.

---

## ğŸ› ï¸ Tecnologias Utilizadas

![Python](https://img.shields.io/badge/python-3.10-blue?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)
![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)
![MLflow](https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=mlflow&logoColor=white)
![SQLite](https://img.shields.io/badge/sqlite-%2307405e.svg?style=for-the-badge&logo=sqlite&logoColor=white)

---

## ğŸš€ Funcionalidades principais

- **Deep Learning com PyTorch Lightning:** implementaÃ§Ã£o de rede LSTM otimizada para sÃ©ries temporais.
- **API Inteligente (Stateful):** O endpoint de prediÃ§Ã£o carrega automaticamente as configuraÃ§Ãµes usadas no treino (sÃ­mbolo, janela temporal e features), evitando erros manuais.
- **Experiment Tracking (MLflow):** rastreio completo de mÃ©tricas (RMSE, MAE, RÂ²), hiperparÃ¢metros e artefatos.
- **Monitoramento de hardware:** hooks personalizados para monitorar uso de CPU, RAM e GPU (VRAM) durante treino e inferÃªncia.
- **Arquitetura hÃ­brida:** suporte transparente para execuÃ§Ã£o em Docker (CPU/produÃ§Ã£o) e local (GPU/desenvolvimento).
- **PrevenÃ§Ã£o de Data Leakage:** pipeline de dados com normalizaÃ§Ã£o ajustada apenas no conjunto de treino.

---

## ğŸ“‚ Estrutura do projeto

```text
/
â”œâ”€â”€ app/                    # LÃ³gica da aplicaÃ§Ã£o (API)
â”‚   â”œâ”€â”€ main.py             # Entrypoint da API e rotas
â”‚   â”œâ”€â”€ services.py         # Orquestrador de treino e inferÃªncia (Singleton)
â”‚   â”œâ”€â”€ schemas.py          # Contratos de dados (Pydantic)
â”‚   â”œâ”€â”€ utils.py            # UtilitÃ¡rios de Hardware (GPU)
â”‚   â””â”€â”€ config.py           # ConfiguraÃ§Ãµes globais e logs
â”‚
â”œâ”€â”€ ml/                     # NÃºcleo de Machine Learning
â”‚   â”œâ”€â”€ model.py            # Arquitetura LSTM (LightningModule)
â”‚   â”œâ”€â”€ dataset.py          # ETL e prÃ©-processamento (yfinance)
â”‚   â””â”€â”€ callbacks.py        # Monitoramento de hardware
â”‚
â”œâ”€â”€ models/                 # PersistÃªncia de modelos (.pth e .pkl)
â”œâ”€â”€ mlruns/                 # Logs locais do MLflow (se rodar localmente)
â”œâ”€â”€ Dockerfile              # DefiniÃ§Ã£o da imagem da API
â”œâ”€â”€ docker-compose.yml      # OrquestraÃ§Ã£o (API + MLflow + SQLite)
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
â””â”€â”€ .gitignore              # Arquivos ignorados pelo Git
```

---

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

O projeto foi desenhado seguindo princÃ­pios de **Clean Architecture** e **MLOps**, visando a separaÃ§Ã£o clara entre a ciÃªncia de dados e a engenharia de software.

### 1. NÃºcleo de InteligÃªncia (Pasta `ml/`)
Optou-se por uma arquitetura **LSTM (Long Short-Term Memory)** devido Ã  sua capacidade superior de capturar dependÃªncias de longo prazo em sÃ©ries temporais financeiras.
* **Framework:** PyTorch Lightning foi escolhido para abstrair o *loop* de treino, facilitar o uso de GPU e integrar nativamente com o MLflow.
* **Horizonte FlexÃ­vel (1 a N dias):** O modelo suporta treinamento dinÃ¢mico para diferentes horizontes de previsÃ£o. AtravÃ©s do parÃ¢metro `prediction_steps`, Ã© possÃ­vel treinar redes especializadas em prever o dia seguinte (D+1), a prÃ³xima semana (D+7) ou qualquer intervalo arbitrÃ¡rio (D+N).

### 2. Camada de AplicaÃ§Ã£o (Pasta `app/`)
A API foi construÃ­da sobre o **FastAPI** pela sua natureza assÃ­ncrona e validaÃ§Ã£o automÃ¡tica de tipos (Pydantic).
* **PadrÃ£o Singleton:** A classe `ModelService` (`app/services.py`) implementa o padrÃ£o Singleton para manter o modelo carregado em memÃ³ria. Isso evita o custo de I/O a cada requisiÃ§Ã£o, garantindo latÃªncia de inferÃªncia na ordem de milissegundos.
* **InferÃªncia Inteligente:** A API gerencia o estado dos modelos. Ao carregar um modelo treinado, ela recupera automaticamente o *lookback* (tamanho da janela) e as *features* exatas usadas no treinamento, garantindo que a entrada da prediÃ§Ã£o seja sempre compatÃ­vel.

### 3. Infraestrutura HÃ­brida
A soluÃ§Ã£o suporta dois modos de execuÃ§Ã£o sem alteraÃ§Ã£o de cÃ³digo, graÃ§as Ã  gestÃ£o dinÃ¢mica de variÃ¡veis de ambiente:
* **Ambiente Docker (ProduÃ§Ã£o):** Focado em estabilidade e portabilidade (CPU). O banco de dados do MLflow Ã© persistido em volume Docker.
* **Ambiente Local (Desenvolvimento):** Focado em performance de treino, permitindo o uso direto de **GPUs NVIDIA** (via CUDA) para acelerar o aprendizado profundo.

---

## ğŸ“Š Fonte de Dados

O sistema consome dados histÃ³ricos do mercado financeiro em tempo real, garantindo que o modelo seja treinado com informaÃ§Ãµes atualizadas.

- **Provedor:** Yahoo Finance (via biblioteca `yfinance`).
- **Flexibilidade:** A API aceita qualquer *ticker* de aÃ§Ã£o listado na bolsa (ex: `DIS`, `AAPL`, `PETR4.SA`, `^BVSP`).
- **Coleta Sob Demanda:** Os dados nÃ£o sÃ£o estÃ¡ticos; eles sÃ£o baixados dinamicamente no momento do treino (`POST /train`) com base no intervalo de datas (`start_date`, `end_date`) fornecido pelo usuÃ¡rio.
---

## ğŸ› ï¸ Como executar

### OpÃ§Ã£o A: Via Docker (recomendado)
Esta opÃ§Ã£o garante um ambiente isolado e reproduzÃ­vel. O MLflow e a API subirÃ£o automaticamente.

Certifique-se de ter Docker e Docker Compose instalados. Na raiz do projeto, execute:

```bash
docker-compose up --build
```

A seguir, os serviÃ§os que serÃ£o iniciados:
- API (Swagger): http://localhost:8000/docs
- MLflow UI: http://localhost:5000

### OpÃ§Ã£o B: ExecuÃ§Ã£o local (desenvolvimento/GPU)
Use esta opÃ§Ã£o se desejar treinar usando uma GPU NVIDIA (CUDA).

Crie e ative um ambiente virtual:

```bash
python -m venv venv
# Windows:
.\venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

Inicie a aplicaÃ§Ã£o (como mÃ³dulo):

```bash
python -m app.main
```

(Nota: ao rodar localmente, o MLflow abrirÃ¡ uma interface prÃ³pria em background na porta 5000.)

---

## âš ï¸ SoluÃ§Ã£o de Problemas Comuns

### 1. Erro: "Port is already allocated"
Se ao rodar o Docker aparecer erro nas portas `8000` ou `5000`, certifique-se de que nÃ£o hÃ¡ outro serviÃ§o rodando (ou uma execuÃ§Ã£o antiga do prÃ³prio projeto).
* **SoluÃ§Ã£o:** Pare os containers antigos com `docker-compose down` ou altere o mapeamento no `docker-compose.yml`.

### 2. Erro de PermissÃ£o no Banco de Dados (SQLite)
Se o MLflow reclamar de "readonly database" ou "unable to open database file".
* **SoluÃ§Ã£o:** O arquivo `docker-compose.yml` jÃ¡ trata isso mapeando a pasta `/mlflow_data`. Se persistir, apague a pasta `mlflow_data` local e reinicie o Docker.

### 3. GPU nÃ£o detectada (ExecuÃ§Ã£o Local)
Se o log mostrar `CUDA available: False` mesmo vocÃª tendo uma placa NVIDIA.
* **SoluÃ§Ã£o:** Verifique se instalou o [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads) compatÃ­vel com seu PyTorch. O projeto funcionarÃ¡ normalmente em CPU (apenas mais lento).

---

## ğŸ“¡ Utilizando a API

Acesse a documentaÃ§Ã£o interativa (Swagger UI): http://localhost:8000/docs

### 1. Treinar um modelo (`POST /train`)
Nesta etapa, vocÃª define a arquitetura temporal (lookback) e o alvo da previsÃ£o.

Exemplo de payload:

```json
{
  "model_name": "disney_v1",
  "symbol": "DIS",
  "start_date": "2018-01-01",
  "end_date": "2025-10-30",
  "epochs": 5,
  "batch_size": 32,
  "prediction_steps": 1,
  "lookback_days": 60
}
```

2. Fazer uma previsÃ£o (POST /predict)  
   Exemplo de payload:

```json
{
  "model_name": "disney_v1"
}
```

---

### ğŸ“˜ Detalhamento dos ParÃ¢metros

#### 1. Treinamento (`POST /train`)
| ParÃ¢metro | Tipo | DescriÃ§Ã£o |
| :--- | :--- | :--- |
| `model_name` | `string` | Identificador Ãºnico para salvar o modelo (ex: "v1_disney"). |
| `symbol` | `string` | Ticker da aÃ§Ã£o no Yahoo Finance (ex: "DIS", "AAPL", "PETR4.SA"). |
| `start_date` | `yyyy-mm-dd` | InÃ­cio do perÃ­odo histÃ³rico de dados para treino. |
| `end_date` | `yyyy-mm-dd` | Fim do perÃ­odo histÃ³rico. |
| `epochs` | `int` | Ciclos completos de treinamento sobre o dataset. |
| `batch_size` | `int` | Quantidade de dados processados por lote. |
| `prediction_steps` | `int` | **Horizonte:** Quantos dias Ã  frente queremos prever (1=amanhÃ£, 7=semana que vem). |
| `lookback_days` | `int` | **Janela de MemÃ³ria:** Quantos dias passados a LSTM analisarÃ¡ para tomar decisÃ£o. |

#### 2. PrediÃ§Ã£o (`POST /predict`)
| ParÃ¢metro | Tipo | DescriÃ§Ã£o |
| :--- | :--- | :--- |
| `model_name` | `string` | Nome do modelo previamente treinado a ser carregado. |

---

## ğŸ“Š Monitoramento e mÃ©tricas

Acesse o dashboard do MLflow: http://localhost:5000

O sistema registra automaticamente:
- MÃ©tricas de negÃ³cio: preÃ§o previsto vs real.
- MÃ©tricas de modelo: loss, MAE, RMSE, MAPE, RÂ².
- Infraestrutura: consumo de RAM (MB), uso de CPU (%) e GPU VRAM (se disponÃ­vel).
- LatÃªncia: tempo de resposta da inferÃªncia.

---

## ğŸ§  Detalhes tÃ©cnicos

### PrevenÃ§Ã£o de Data Leakage
Um erro comum em sÃ©ries temporais Ã© normalizar o dataset inteiro antes da divisÃ£o. Neste projeto, o MinMaxScaler Ã© ajustado (fit) apenas nos dados de treino (primeiros 80%) e aplicado (transform) nos dados de validaÃ§Ã£o. Assim, o modelo nÃ£o tem acesso a estatÃ­sticas do futuro.

### PersistÃªncia de Metadados e ConsistÃªncia
Para garantir a robustez da API, nÃ£o salvamos apenas os pesos da rede neural (`.pth`). Salvamos tambÃ©m um arquivo de artefatos (`.pkl`) contendo:
- O **Scaler** ajustado (para desnormalizar a saÃ­da corretamente).
- A lista de **Features** usadas (para garantir que a API baixe as colunas corretas, ex: Open, Close, Volume).
- Os hiperparÃ¢metros estruturais (**Lookback** e **Horizonte**).

Isso permite que a API evolua (ex: adicionando novos indicadores tÃ©cnicos no futuro) sem quebrar a compatibilidade com modelos antigos.
---

## ğŸ”® PrÃ³ximos Passos e Melhorias Futuras

Para evoluir este projeto em um ambiente produtivo real, as seguintes implementaÃ§Ãµes estÃ£o no roadmap:

1.  **Feature Engineering AvanÃ§ada:** Incluir indicadores tÃ©cnicos (RSI, MACD, Bandas de Bollinger) alÃ©m dos preÃ§os puros (OHLCV) para enriquecer o contexto do modelo.
2.  **Hyperparameter Tuning:** Implementar [Optuna](https://optuna.org/) para busca automÃ¡tica dos melhores parÃ¢metros da LSTM (learning rate, nÃºmero de camadas, neurÃ´nios).
3.  **Deployment na Nuvem:** Criar pipeline de CI/CD (GitHub Actions) para deploy automÃ¡tico na AWS (ECS ou SageMaker).
4.  **AutenticaÃ§Ã£o na API:** Adicionar camada de seguranÃ§a (JWT) nos endpoints da FastAPI.

---

## ğŸ“ Autores

Projeto desenvolvido por:
* **Celso Lopes** - RM: 364112 

Desenvolvido para o **Tech Challenge Fase 4** - PÃ³s-Tech Machine Learning Engineering (FIAP).