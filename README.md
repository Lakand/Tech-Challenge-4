# ğŸ“ˆ Tech Challenge - Fase 4: Stock Prediction API

Este projeto consiste em uma soluÃ§Ã£o End-to-End de Machine Learning Engineering desenvolvida para o Tech Challenge da Fase 4 (PÃ³s-Tech FIAP).

O objetivo Ã© prever preÃ§os de fechamento de aÃ§Ãµes utilizando redes neurais LSTM (Long Short-Term Memory), servidas por uma API RESTful modularizada, conteinerizada e monitorada.

## ğŸš€ Funcionalidades principais

- Deep Learning com PyTorch Lightning: implementaÃ§Ã£o de rede LSTM otimizada para sÃ©ries temporais.
- API RESTful (FastAPI): endpoints assÃ­ncronos para treinamento e inferÃªncia em tempo real.
- Experiment Tracking (MLflow): rastreio completo de mÃ©tricas (RMSE, MAE, RÂ²), hiperparÃ¢metros e artefatos.
- Monitoramento de hardware: hooks personalizados para monitorar uso de CPU, RAM e GPU (VRAM) durante treino e inferÃªncia.
- Arquitetura hÃ­brida: suporte transparente para execuÃ§Ã£o em Docker (CPU/produÃ§Ã£o) e local (GPU/desenvolvimento).
- PrevenÃ§Ã£o de Data Leakage: pipeline de dados com normalizaÃ§Ã£o ajustada apenas no conjunto de treino.

---

## ğŸ“‚ Estrutura do projeto

```text
/
â”œâ”€â”€ app/                    # LÃ³gica da aplicaÃ§Ã£o (API)
â”‚   â”œâ”€â”€ main.py             # Entrypoint da API e rotas
â”‚   â”œâ”€â”€ services.py         # Orquestrador de treino e inferÃªncia (Singleton)
â”‚   â”œâ”€â”€ schemas.py          # Contratos de dados (Pydantic)
â”‚   â””â”€â”€ config.py           # ConfiguraÃ§Ãµes globais e logs
â”‚
â”œâ”€â”€ ml/                     # NÃºcleo de Machine Learning
â”‚   â”œâ”€â”€ model.py            # Arquitetura LSTM (LightningModule)
â”‚   â”œâ”€â”€ dataset.py          # ETL e prÃ©-processamento (yfinance)
â”‚   â””â”€â”€ callbacks.py        # Monitoramento de hardware
â”‚
â”œâ”€â”€ models/                 # PersistÃªncia de modelos (.pth e .pkl)
â”œâ”€â”€ mlruns/                 # Logs locais do MLflow (se rodar localmente)
â”œâ”€â”€ Dockerfile              # DefiniÃ§Ã£o da imagem da API
â”œâ”€â”€ docker-compose.yml      # OrquestraÃ§Ã£o (API + MLflow + SQLite)
â””â”€â”€ requirements.txt        # DependÃªncias do projeto
```

---

## ğŸ› ï¸ Como executar

### OpÃ§Ã£o A: Via Docker (recomendado)
Esta opÃ§Ã£o garante um ambiente isolado e reproduzÃ­vel. O MLflow e a API subirÃ£o automaticamente.

Certifique-se de ter Docker e Docker Compose instalados. Na raiz do projeto, execute:

```bash
docker-compose up --build
```

A seguir, os serviÃ§os que serÃ£o iniciados:
- API (Swagger): http://localhost:8000/docs
- MLflow UI: http://localhost:5000

### OpÃ§Ã£o B: ExecuÃ§Ã£o local (desenvolvimento/GPU)
Use esta opÃ§Ã£o se desejar treinar usando uma GPU NVIDIA (CUDA).

Crie e ative um ambiente virtual:

```bash
python -m venv venv
# Windows:
.\venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

Inicie a aplicaÃ§Ã£o (como mÃ³dulo):

```bash
python -m app.main
```

(Nota: ao rodar localmente, o MLflow abrirÃ¡ uma interface prÃ³pria em background na porta 5000.)

---

## ğŸ“¡ Utilizando a API

Acesse a documentaÃ§Ã£o interativa (Swagger UI): http://localhost:8000/docs

1. Treinar um modelo (POST /train)  
   Exemplo de payload:

```json
{
  "model_name": "disney_v1",
  "symbol": "DIS",
  "start_date": "2018-01-01",
  "end_date": "2025-10-30",
  "epochs": 5,
  "batch_size": 32,
  "prediction_steps": 1
}
```

2. Fazer uma previsÃ£o (POST /predict)  
   Exemplo de payload:

```json
{
  "model_name": "disney_v1",
  "symbol": "DIS",
  "lookback_days": 60
}
```

---

## ğŸ“Š Monitoramento e mÃ©tricas

Acesse o dashboard do MLflow: http://localhost:5000

O sistema registra automaticamente:
- MÃ©tricas de negÃ³cio: preÃ§o previsto vs real.
- MÃ©tricas de modelo: loss, MAE, RMSE, MAPE, RÂ².
- Infraestrutura: consumo de RAM (MB), uso de CPU (%) e GPU VRAM (se disponÃ­vel).
- LatÃªncia: tempo de resposta da inferÃªncia.

---

## ğŸ§  Detalhes tÃ©cnicos

### PrevenÃ§Ã£o de Data Leakage
Um erro comum em sÃ©ries temporais Ã© normalizar o dataset inteiro antes da divisÃ£o. Neste projeto, o MinMaxScaler Ã© ajustado (fit) apenas nos dados de treino (primeiros 80%) e aplicado (transform) nos dados de validaÃ§Ã£o. Assim, o modelo nÃ£o tem acesso a estatÃ­sticas do futuro.

### PersistÃªncia robusta
Ao salvar um modelo, geramos dois arquivos na pasta models/:

- {nome}.pth: pesos da rede neural (state dict).
- {nome}.pkl: metadados (scaler ajustado, nÃºmero de features, horizonte de previsÃ£o), necessÃ¡rios para a desnormalizaÃ§Ã£o na inferÃªncia.

---

## ğŸ“ Autores
Desenvolvido para o Tech Challenge Fase 4 - PÃ³s-Tech Machine Learning Engineering.