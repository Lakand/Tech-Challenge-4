# üìà Tech Challenge - Fase 4: Stock Prediction API

Este projeto consiste em uma solu√ß√£o End-to-End de Machine Learning Engineering desenvolvida para o Tech Challenge da Fase 4 (P√≥s-Tech FIAP).

O objetivo √© prever pre√ßos de fechamento de a√ß√µes utilizando redes neurais LSTM (Long Short-Term Memory), servidas por uma API RESTful modularizada, conteinerizada e monitorada.

---

## üõ†Ô∏è Tecnologias Utilizadas

![Python](https://img.shields.io/badge/python-3.10-blue?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)
![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)
![MLflow](https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=mlflow&logoColor=white)
![SQLite](https://img.shields.io/badge/sqlite-%2307405e.svg?style=for-the-badge&logo=sqlite&logoColor=white)

---

## üöÄ Funcionalidades principais

- **Deep Learning com PyTorch Lightning:** implementa√ß√£o de rede LSTM otimizada para s√©ries temporais.
- **API Inteligente (Stateful):** O endpoint de predi√ß√£o carrega automaticamente as configura√ß√µes usadas no treino (s√≠mbolo, janela temporal e features), evitando erros manuais.
- **Experiment Tracking (MLflow):** rastreio completo de m√©tricas (RMSE, MAE, R¬≤), hiperpar√¢metros e artefatos.
- **Monitoramento de hardware:** hooks personalizados para monitorar uso de CPU, RAM e GPU (VRAM) durante treino e infer√™ncia.
- **Arquitetura h√≠brida:** suporte transparente para execu√ß√£o em Docker (CPU/produ√ß√£o) e local (GPU/desenvolvimento).
- **Preven√ß√£o de Data Leakage:** pipeline de dados com normaliza√ß√£o ajustada apenas no conjunto de treino.

---

## üìÇ Estrutura do projeto

```text
/
‚îú‚îÄ‚îÄ app/                    # L√≥gica da aplica√ß√£o (API)
‚îÇ   ‚îú‚îÄ‚îÄ main.py             # Entrypoint da API e rotas
‚îÇ   ‚îú‚îÄ‚îÄ services.py         # Orquestrador de treino e infer√™ncia (Singleton)
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py          # Contratos de dados (Pydantic)
‚îÇ   ‚îú‚îÄ‚îÄ utils.py            # Utilit√°rios de Hardware (GPU)
‚îÇ   ‚îî‚îÄ‚îÄ config.py           # Configura√ß√µes globais e logs
‚îÇ
‚îú‚îÄ‚îÄ ml/                     # N√∫cleo de Machine Learning
‚îÇ   ‚îú‚îÄ‚îÄ model.py            # Arquitetura LSTM (LightningModule)
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py          # ETL e pr√©-processamento (yfinance)
‚îÇ   ‚îî‚îÄ‚îÄ callbacks.py        # Monitoramento de hardware
‚îÇ
‚îú‚îÄ‚îÄ models/                 # Persist√™ncia de modelos (.pth e .pkl)
‚îú‚îÄ‚îÄ mlruns/                 # Logs locais do MLflow (se rodar localmente)
‚îú‚îÄ‚îÄ Dockerfile              # Defini√ß√£o da imagem da API
‚îú‚îÄ‚îÄ docker-compose.yml      # Orquestra√ß√£o (API + MLflow + SQLite)
‚îú‚îÄ‚îÄ requirements.txt        # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ .gitignore              # Arquivos ignorados pelo Git
```

---

## üèóÔ∏è Arquitetura da Solu√ß√£o

O projeto foi desenhado seguindo princ√≠pios de **Clean Architecture** e **MLOps**, visando a separa√ß√£o clara entre a ci√™ncia de dados e a engenharia de software.

### 1. N√∫cleo de Intelig√™ncia (Pasta `ml/`)
Optou-se por uma arquitetura **LSTM (Long Short-Term Memory)** devido √† sua capacidade superior de capturar depend√™ncias de longo prazo em s√©ries temporais financeiras.
* **Framework:** PyTorch Lightning foi escolhido para abstrair o *loop* de treino, facilitar o uso de GPU e integrar nativamente com o MLflow.
* **Horizonte Flex√≠vel (1 a N dias):** O modelo suporta treinamento din√¢mico para diferentes horizontes de previs√£o. Atrav√©s do par√¢metro `prediction_steps`, √© poss√≠vel treinar redes especializadas em prever o dia seguinte (D+1), a pr√≥xima semana (D+7) ou qualquer intervalo arbitr√°rio (D+N).

### 2. Camada de Aplica√ß√£o (Pasta `app/`)
A API foi constru√≠da sobre o **FastAPI** pela sua natureza ass√≠ncrona e valida√ß√£o autom√°tica de tipos (Pydantic).
* **Padr√£o Singleton:** A classe `ModelService` (`app/services.py`) implementa o padr√£o Singleton para manter o modelo carregado em mem√≥ria. Isso evita o custo de I/O a cada requisi√ß√£o, garantindo lat√™ncia de infer√™ncia na ordem de milissegundos.
* **Infer√™ncia Inteligente:** A API gerencia o estado dos modelos. Ao carregar um modelo treinado, ela recupera automaticamente o *lookback* (tamanho da janela) e as *features* exatas usadas no treinamento, garantindo que a entrada da predi√ß√£o seja sempre compat√≠vel.

### 3. Infraestrutura H√≠brida
A solu√ß√£o suporta dois modos de execu√ß√£o sem altera√ß√£o de c√≥digo, gra√ßas √† gest√£o din√¢mica de vari√°veis de ambiente:
* **Ambiente Docker (Produ√ß√£o):** Focado em estabilidade e portabilidade (CPU). O banco de dados do MLflow √© persistido em volume Docker.
* **Ambiente Local (Desenvolvimento):** Focado em performance de treino, permitindo o uso direto de **GPUs NVIDIA** (via CUDA) para acelerar o aprendizado profundo.

---

## üìä Fonte de Dados

O sistema consome dados hist√≥ricos do mercado financeiro em tempo real, garantindo que o modelo seja treinado com informa√ß√µes atualizadas.

- **Provedor:** Yahoo Finance (via biblioteca `yfinance`).
- **Flexibilidade:** A API aceita qualquer *ticker* de a√ß√£o listado na bolsa (ex: `DIS`, `AAPL`, `PETR4.SA`, `^BVSP`).
- **Coleta Sob Demanda:** Os dados n√£o s√£o est√°ticos; eles s√£o baixados dinamicamente no momento do treino (`POST /train`) com base no intervalo de datas (`start_date`, `end_date`) fornecido pelo usu√°rio.

Para fins de valida√ß√£o do desafio, foram realizados testes utilizando a√ß√µes do ticker DIS (Disney).


---

## üõ†Ô∏è Como executar

### Op√ß√£o A: Via Docker (recomendado)
Esta op√ß√£o garante um ambiente isolado e reproduz√≠vel. O MLflow e a API subir√£o automaticamente.

Certifique-se de ter Docker e Docker Compose instalados. Na raiz do projeto, execute:

```bash
docker-compose up --build
```

A seguir, os servi√ßos que ser√£o iniciados:
- API (Swagger): http://localhost:8000/docs
- MLflow UI: http://localhost:5000

### Op√ß√£o B: Execu√ß√£o local (desenvolvimento/GPU)
Use esta op√ß√£o se desejar treinar usando uma GPU NVIDIA (CUDA).

Crie e ative um ambiente virtual:

```bash
python -m venv venv
# Windows:
.\venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

Instale as depend√™ncias:

```bash
pip install -r requirements.txt
```

Inicie a aplica√ß√£o (como m√≥dulo):

```bash
python -m app.main
```

(Nota: ao rodar localmente, o MLflow abrir√° uma interface pr√≥pria em background na porta 5000.)

---

## ‚ö†Ô∏è Solu√ß√£o de Problemas Comuns

### 1. Erro: "Port is already allocated"
Se ao rodar o Docker aparecer erro nas portas `8000` ou `5000`, certifique-se de que n√£o h√° outro servi√ßo rodando (ou uma execu√ß√£o antiga do pr√≥prio projeto).
* **Solu√ß√£o:** Pare os containers antigos com `docker-compose down` ou altere o mapeamento no `docker-compose.yml`.

### 2. Erro de Permiss√£o no Banco de Dados (SQLite)
Se o MLflow reclamar de "readonly database" ou "unable to open database file".
* **Solu√ß√£o:** O arquivo `docker-compose.yml` j√° trata isso mapeando a pasta `/mlflow_data`. Se persistir, apague a pasta `mlflow_data` local e reinicie o Docker.

### 3. GPU n√£o detectada (Execu√ß√£o Local)
Se o log mostrar `CUDA available: False` mesmo voc√™ tendo uma placa NVIDIA.
* **Solu√ß√£o:** Verifique se instalou o [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads) compat√≠vel com seu PyTorch. O projeto funcionar√° normalmente em CPU (apenas mais lento).

---

## üì° Utilizando a API

Acesse a documenta√ß√£o interativa (Swagger UI): http://localhost:8000/docs

### 1. Treinar um modelo (`POST /train`)
Nesta etapa, voc√™ define a arquitetura temporal (lookback) e o alvo da previs√£o.

Exemplo de payload:

```json
{
  "model_name": "disney_v1",
  "symbol": "DIS",
  "start_date": "2018-01-01",
  "end_date": "2025-10-30",
  "epochs": 5,
  "batch_size": 32,
  "prediction_steps": 1,
  "lookback_days": 60
}
```

2. Fazer uma previs√£o (POST /predict)  
   Exemplo de payload:

```json
{
  "model_name": "disney_v1"
}
```

---

### üìò Detalhamento dos Par√¢metros

#### 1. Treinamento (`POST /train`)
| Par√¢metro | Tipo | Descri√ß√£o |
| :--- | :--- | :--- |
| `model_name` | `string` | Identificador √∫nico para salvar o modelo (ex: "v1_disney"). |
| `symbol` | `string` | Ticker da a√ß√£o no Yahoo Finance (ex: "DIS", "AAPL", "PETR4.SA"). |
| `start_date` | `yyyy-mm-dd` | In√≠cio do per√≠odo hist√≥rico de dados para treino. |
| `end_date` | `yyyy-mm-dd` | Fim do per√≠odo hist√≥rico. |
| `epochs` | `int` | Ciclos completos de treinamento sobre o dataset. |
| `batch_size` | `int` | Quantidade de dados processados por lote. |
| `prediction_steps` | `int` | **Horizonte:** Quantos dias √† frente queremos prever (1=amanh√£, 7=semana que vem). |
| `lookback_days` | `int` | **Janela de Mem√≥ria:** Quantos dias passados a LSTM analisar√° para tomar decis√£o. |

#### 2. Predi√ß√£o (`POST /predict`)
| Par√¢metro | Tipo | Descri√ß√£o |
| :--- | :--- | :--- |
| `model_name` | `string` | Nome do modelo previamente treinado a ser carregado. |

---

## üìä Monitoramento e m√©tricas

Acesse o dashboard do MLflow: http://localhost:5000

O sistema registra automaticamente:
- M√©tricas de neg√≥cio: pre√ßo previsto vs real.
- M√©tricas de modelo: loss, MAE, RMSE, MAPE, R¬≤.
- Infraestrutura: consumo de RAM (MB), uso de CPU (%) e GPU VRAM (se dispon√≠vel).
- Lat√™ncia: tempo de resposta da infer√™ncia.

---

### üìà Resultados Obtidos (Epoch 199)

Abaixo, apresentamos a converg√™ncia do modelo durante um treinamento de 199 √©pocas. O modelo final atingiu estabilidade com m√©tricas competitivas para s√©ries temporais financeiras.

| Converg√™ncia (Loss) | Qualidade do Ajuste (R¬≤ Score) |
|:---:|:---:|
| ![Loss Graph](docs/img/val_loss.png) | ![R2 Graph](docs/img/val_r2.png) |
| *A curva de perda (MSE) estabiliza rapidamente, indicando aprendizado efetivo sem underfitting severo.* | *O R¬≤ pr√≥ximo de 0.77 demonstra que o modelo consegue explicar a maior parte da vari√¢ncia dos pre√ßos.* |

#### üìä M√©tricas Finais (Valida√ß√£o):

| M√©trica | Valor Final | Significado |
| :--- | :--- | :--- |
| **Val Loss (MSE)** | `0.000196` | Erro Quadr√°tico M√©dio. A fun√ß√£o de custo minimizada pelo modelo. |
| **MAE** | `0.00942` | *Mean Absolute Error*. O erro m√©dio absoluto em d√≥lares/reais (escala normalizada). |
| **MAPE** | `0.0601` | *Mean Absolute Percentage Error*. A porcentagem m√©dia de erro por predi√ß√£o. |
| **RMSE** | `0.013` | *Root Mean Squared Error*. Penaliza erros maiores mais severamente que o MAE. |
| **R¬≤ Score** | `0.771` | *Coefficient of Determination*. Indica qu√£o bem o modelo se ajusta aos dados (1.0 √© perfeito). |

*(Valores referentes ao √∫ltimo checkpoint salvo na √©poca 199)*

---

## üß† Detalhes t√©cnicos

### Preven√ß√£o de Data Leakage
Um erro comum em s√©ries temporais √© normalizar o dataset inteiro antes da divis√£o. Neste projeto, o MinMaxScaler √© ajustado (fit) apenas nos dados de treino (primeiros 80%) e aplicado (transform) nos dados de valida√ß√£o. Assim, o modelo n√£o tem acesso a estat√≠sticas do futuro.

### Persist√™ncia de Metadados e Consist√™ncia
Para garantir a robustez da API, n√£o salvamos apenas os pesos da rede neural (`.pth`). Salvamos tamb√©m um arquivo de artefatos (`.pkl`) contendo:
- O **Scaler** ajustado (para desnormalizar a sa√≠da corretamente).
- A lista de **Features** usadas (para garantir que a API baixe as colunas corretas, ex: Open, Close, Volume).
- Os hiperpar√¢metros estruturais (**Lookback** e **Horizonte**).

Isso permite que a API evolua (ex: adicionando novos indicadores t√©cnicos no futuro) sem quebrar a compatibilidade com modelos antigos.
---

## üîÆ Pr√≥ximos Passos e Melhorias Futuras

Para evoluir este projeto em um ambiente produtivo real, as seguintes implementa√ß√µes est√£o no roadmap:

1.  **Feature Engineering Avan√ßada:** Incluir indicadores t√©cnicos (RSI, MACD, Bandas de Bollinger) al√©m dos pre√ßos puros (OHLCV) para enriquecer o contexto do modelo.
2.  **Hyperparameter Tuning:** Implementar [Optuna](https://optuna.org/) para busca autom√°tica dos melhores par√¢metros da LSTM (learning rate, n√∫mero de camadas, neur√¥nios).
3.  **Deployment na Nuvem:** Criar pipeline de CI/CD (GitHub Actions) para deploy autom√°tico na AWS (ECS ou SageMaker).
4.  **Autentica√ß√£o na API:** Adicionar camada de seguran√ßa (JWT) nos endpoints da FastAPI.

---

## üìù Autores

Projeto desenvolvido por:
* **Celso Lopes** - RM: 364112 

Desenvolvido para o **Tech Challenge Fase 4** - P√≥s-Tech Machine Learning Engineering (FIAP).

---

## ‚ö†Ô∏è Disclaimer

Este projeto tem fins estritamente educacionais para demonstra√ß√£o de conhecimentos em Engenharia de Machine Learning. As previs√µes geradas pelo modelo **n√£o constituem recomenda√ß√£o de investimento**. O mercado financeiro √© vol√°til e modelos baseados puramente em pre√ßos passados podem n√£o capturar eventos ex√≥genos.