# ğŸ“ˆ Tech Challenge - Fase 4: Stock Prediction API

Este projeto consiste em uma soluÃ§Ã£o End-to-End de Machine Learning Engineering desenvolvida para o Tech Challenge da Fase 4 (PÃ³s-Tech FIAP).

O objetivo Ã© prever preÃ§os de fechamento de aÃ§Ãµes utilizando redes neurais LSTM (Long Short-Term Memory), servidas por uma API RESTful modularizada, conteinerizada e monitorada.

## ğŸ› ï¸ Tecnologias Utilizadas

![Python](https://img.shields.io/badge/python-3.10-blue?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)
![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white)
![MLflow](https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=mlflow&logoColor=white)
![SQLite](https://img.shields.io/badge/sqlite-%2307405e.svg?style=for-the-badge&logo=sqlite&logoColor=white)

---

## ğŸš€ Funcionalidades principais

- Deep Learning com PyTorch Lightning: implementaÃ§Ã£o de rede LSTM otimizada para sÃ©ries temporais.
- API RESTful (FastAPI): endpoints assÃ­ncronos para treinamento e inferÃªncia em tempo real.
- Experiment Tracking (MLflow): rastreio completo de mÃ©tricas (RMSE, MAE, RÂ²), hiperparÃ¢metros e artefatos.
- Monitoramento de hardware: hooks personalizados para monitorar uso de CPU, RAM e GPU (VRAM) durante treino e inferÃªncia.
- Arquitetura hÃ­brida: suporte transparente para execuÃ§Ã£o em Docker (CPU/produÃ§Ã£o) e local (GPU/desenvolvimento).
- PrevenÃ§Ã£o de Data Leakage: pipeline de dados com normalizaÃ§Ã£o ajustada apenas no conjunto de treino.

---

## ğŸ“‚ Estrutura do projeto

```text
/
â”œâ”€â”€ app/                    # LÃ³gica da aplicaÃ§Ã£o (API)
â”‚   â”œâ”€â”€ main.py             # Entrypoint da API e rotas
â”‚   â”œâ”€â”€ services.py         # Orquestrador de treino e inferÃªncia (Singleton)
â”‚   â”œâ”€â”€ schemas.py          # Contratos de dados (Pydantic)
â”‚   â”œâ”€â”€ utils.py            # UtilitÃ¡rios de Hardware (GPU)
â”‚   â””â”€â”€ config.py           # ConfiguraÃ§Ãµes globais e logs
â”‚
â”œâ”€â”€ ml/                     # NÃºcleo de Machine Learning
â”‚   â”œâ”€â”€ model.py            # Arquitetura LSTM (LightningModule)
â”‚   â”œâ”€â”€ dataset.py          # ETL e prÃ©-processamento (yfinance)
â”‚   â””â”€â”€ callbacks.py        # Monitoramento de hardware
â”‚
â”œâ”€â”€ models/                 # PersistÃªncia de modelos (.pth e .pkl)
â”œâ”€â”€ mlruns/                 # Logs locais do MLflow (se rodar localmente)
â”œâ”€â”€ Dockerfile              # DefiniÃ§Ã£o da imagem da API
â”œâ”€â”€ docker-compose.yml      # OrquestraÃ§Ã£o (API + MLflow + SQLite)
â”œâ”€â”€ requirements.txt        # DependÃªncias do projeto
â””â”€â”€ .gitignore              # Arquivos ignorados pelo Git
```

---

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

O projeto foi desenhado seguindo princÃ­pios de **Clean Architecture** e **MLOps**, visando a separaÃ§Ã£o clara entre a ciÃªncia de dados e a engenharia de software.

### 1. NÃºcleo de InteligÃªncia (Pasta `ml/`)
Optou-se por uma arquitetura **LSTM (Long Short-Term Memory)** devido Ã  sua capacidade superior de capturar dependÃªncias de longo prazo em sÃ©ries temporais financeiras.
* **Framework:** PyTorch Lightning foi escolhido para abstrair o *loop* de treino, facilitar o uso de GPU e integrar nativamente com o MLflow.
* **Horizonte FlexÃ­vel (1 a N dias):** O modelo suporta treinamento dinÃ¢mico para diferentes horizontes de previsÃ£o. AtravÃ©s do parÃ¢metro `prediction_steps`, Ã© possÃ­vel treinar redes especializadas em prever o dia seguinte (D+1), a prÃ³xima semana (D+7) ou qualquer intervalo arbitrÃ¡rio (D+N), ajustando automaticamente o alvo ($y$) durante o processamento dos dados.

### 2. Camada de AplicaÃ§Ã£o (Pasta `app/`)
A API foi construÃ­da sobre o **FastAPI** pela sua natureza assÃ­ncrona e validaÃ§Ã£o automÃ¡tica de tipos (Pydantic).
* **PadrÃ£o Singleton:** A classe `ModelService` (`app/services.py`) implementa o padrÃ£o Singleton para manter o modelo carregado em memÃ³ria. Isso evita o custo de I/O a cada requisiÃ§Ã£o, garantindo latÃªncia de inferÃªncia na ordem de milissegundos.
* **Contratos de Dados:** O uso de schemas (`app/schemas.py`) valida rigorosamente as entradas, garantindo que parÃ¢metros crÃ­ticos como datas e horizontes de previsÃ£o estejam no formato correto.

### 3. Infraestrutura HÃ­brida
A soluÃ§Ã£o suporta dois modos de execuÃ§Ã£o sem alteraÃ§Ã£o de cÃ³digo, graÃ§as Ã  gestÃ£o dinÃ¢mica de variÃ¡veis de ambiente:
* **Ambiente Docker (ProduÃ§Ã£o):** Focado em estabilidade e portabilidade (CPU). O banco de dados do MLflow Ã© persistido em volume Docker.
* **Ambiente Local (Desenvolvimento):** Focado em performance de treino, permitindo o uso direto de **GPUs NVIDIA** (via CUDA) para acelerar o aprendizado profundo.

---

## ğŸ› ï¸ Como executar

### OpÃ§Ã£o A: Via Docker (recomendado)
Esta opÃ§Ã£o garante um ambiente isolado e reproduzÃ­vel. O MLflow e a API subirÃ£o automaticamente.

Certifique-se de ter Docker e Docker Compose instalados. Na raiz do projeto, execute:

```bash
docker-compose up --build
```

A seguir, os serviÃ§os que serÃ£o iniciados:
- API (Swagger): http://localhost:8000/docs
- MLflow UI: http://localhost:5000

### OpÃ§Ã£o B: ExecuÃ§Ã£o local (desenvolvimento/GPU)
Use esta opÃ§Ã£o se desejar treinar usando uma GPU NVIDIA (CUDA).

Crie e ative um ambiente virtual:

```bash
python -m venv venv
# Windows:
.\venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate
```

Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

Inicie a aplicaÃ§Ã£o (como mÃ³dulo):

```bash
python -m app.main
```

(Nota: ao rodar localmente, o MLflow abrirÃ¡ uma interface prÃ³pria em background na porta 5000.)

---

## âš ï¸ SoluÃ§Ã£o de Problemas Comuns

### 1. Erro: "Port is already allocated"
Se ao rodar o Docker aparecer erro nas portas `8000` ou `5000`, certifique-se de que nÃ£o hÃ¡ outro serviÃ§o rodando (ou uma execuÃ§Ã£o antiga do prÃ³prio projeto).
* **SoluÃ§Ã£o:** Pare os containers antigos com `docker-compose down` ou altere o mapeamento no `docker-compose.yml`.

### 2. Erro de PermissÃ£o no Banco de Dados (SQLite)
Se o MLflow reclamar de "readonly database" ou "unable to open database file".
* **SoluÃ§Ã£o:** O arquivo `docker-compose.yml` jÃ¡ trata isso mapeando a pasta `/mlflow_data`, mas se persistir, apague a pasta `mlflow_data` local e reinicie o Docker.

### 3. GPU nÃ£o detectada (ExecuÃ§Ã£o Local)
Se o log mostrar `CUDA available: False` mesmo vocÃª tendo uma placa NVIDIA.
* **SoluÃ§Ã£o:** Verifique se instalou o [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads) compatÃ­vel com seu PyTorch. O projeto funcionarÃ¡ normalmente em CPU (apenas mais lento).

---

## ğŸ“¡ Utilizando a API

Acesse a documentaÃ§Ã£o interativa (Swagger UI): http://localhost:8000/docs

1. Treinar um modelo (POST /train)  
   Exemplo de payload:

```json
{
  "model_name": "disney_v1",
  "symbol": "DIS",
  "start_date": "2018-01-01",
  "end_date": "2025-10-30",
  "epochs": 5,
  "batch_size": 32,
  "prediction_steps": 1
}
```

2. Fazer uma previsÃ£o (POST /predict)  
   Exemplo de payload:

```json
{
  "model_name": "disney_v1",
  "symbol": "DIS",
  "lookback_days": 60
}
```

---

### ğŸ“˜ Detalhamento dos ParÃ¢metros

Entenda a funÃ§Ã£o de cada campo nas requisiÃ§Ãµes:

#### 1. Treinamento (`POST /train`)
| ParÃ¢metro | Tipo | DescriÃ§Ã£o |
| :--- | :--- | :--- |
| `model_name` | `string` | Identificador Ãºnico para salvar o modelo (ex: "v1_disney"). Permite criar mÃºltiplas versÃµes sem sobrescrever. |
| `symbol` | `string` | Ticker da aÃ§Ã£o no Yahoo Finance (ex: "DIS", "AAPL", "PETR4.SA"). O modelo serÃ¡ treinado neste ativo. |
| `start_date` | `yyyy-mm-dd` | InÃ­cio do perÃ­odo histÃ³rico de dados para treino. |
| `end_date` | `yyyy-mm-dd` | Fim do perÃ­odo histÃ³rico. |
| `epochs` | `int` | NÃºmero de vezes que o modelo verÃ¡ o dataset completo. |
| `batch_size` | `int` | Quantidade de dados processados por vez antes de atualizar os pesos. |
| `prediction_steps` | `int` | **Horizonte de PrevisÃ£o:** Define o alvo da prediÃ§Ã£o. Use `1` para prever o dia seguinte ou `N` para prever o preÃ§o daqui a N dias. |

#### 2. PrediÃ§Ã£o (`POST /predict`)
| ParÃ¢metro | Tipo | DescriÃ§Ã£o |
| :--- | :--- | :--- |
| `model_name` | `string` | Nome do arquivo do modelo (`.pth`) a ser carregado da pasta `models/`. |
| `symbol` | `string` | Ticker do ativo para baixar os dados mais recentes (janela de entrada). |
| `lookback_days` | `int` | **Janela de Contexto:** Quantos dias passados o modelo deve analisar para calcular o futuro. |

---

## ğŸ“Š Monitoramento e mÃ©tricas

Acesse o dashboard do MLflow: http://localhost:5000

O sistema registra automaticamente:
- MÃ©tricas de negÃ³cio: preÃ§o previsto vs real.
- MÃ©tricas de modelo: loss, MAE, RMSE, MAPE, RÂ².
- Infraestrutura: consumo de RAM (MB), uso de CPU (%) e GPU VRAM (se disponÃ­vel).
- LatÃªncia: tempo de resposta da inferÃªncia.

---

## ğŸ§  Detalhes tÃ©cnicos

### PrevenÃ§Ã£o de Data Leakage
Um erro comum em sÃ©ries temporais Ã© normalizar o dataset inteiro antes da divisÃ£o. Neste projeto, o MinMaxScaler Ã© ajustado (fit) apenas nos dados de treino (primeiros 80%) e aplicado (transform) nos dados de validaÃ§Ã£o. Assim, o modelo nÃ£o tem acesso a estatÃ­sticas do futuro.

### PersistÃªncia robusta
Ao salvar um modelo, geramos dois arquivos na pasta models/:

- {nome}.pth: pesos da rede neural (state dict).
- {nome}.pkl: metadados (scaler ajustado, nÃºmero de features, horizonte de previsÃ£o), necessÃ¡rios para a desnormalizaÃ§Ã£o na inferÃªncia.

---

## ğŸ”® PrÃ³ximos Passos e Melhorias Futuras

Para evoluir este projeto em um ambiente produtivo real, as seguintes implementaÃ§Ãµes estÃ£o no roadmap:

1.  **Feature Engineering AvanÃ§ada:** Incluir indicadores tÃ©cnicos (RSI, MACD, Bandas de Bollinger) alÃ©m dos preÃ§os puros (OHLCV) para enriquecer o contexto do modelo.
2.  **Hyperparameter Tuning:** Implementar [Optuna](https://optuna.org/) para busca automÃ¡tica dos melhores parÃ¢metros da LSTM (learning rate, nÃºmero de camadas, neurÃ´nios).
3.  **Deployment na Nuvem:** Criar pipeline de CI/CD (GitHub Actions) para deploy automÃ¡tico na AWS (ECS ou SageMaker).
4.  **AutenticaÃ§Ã£o na API:** Adicionar camada de seguranÃ§a (JWT) nos endpoints da FastAPI.

---

## ğŸ“ Autores

Projeto desenvolvido por:
* **Celso Lopes** - RM: 364112 

Desenvolvido para o **Tech Challenge Fase 4** - PÃ³s-Tech Machine Learning Engineering (FIAP).